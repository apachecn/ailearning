# 入门介绍
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

## 神经元

神经元是神经网络中最基本的结构，也可以说是神经网络的基本单元，它的设计灵感完全来源于生物学上神经元的信息传播机制。我们学过生物的同学都知道，神经元有两种状态：兴奋和抑制。一般情况下，大多数的神经元是处于抑制状态，但是一旦某个神经元收到刺激，导致它的电位超过一个阈值，那么这个神经元就会被激活，处于“兴奋”状态，进而向其他的神经元传播化学物质（其实就是信息）。

## 感知机（perceptron）

感知机（perceptron）是由两层神经元组成的结构，输入层用于接受外界输入信号，输出层（也被称为是感知机的功能层）就是M-P神经元。

## 反向传播——BackPropagation

![/img/DeepLearning/1.入门介绍/反向传播.png)

其中：
* 1.输入数据: i1=0.05, i2=0.10
* 2.输出数据: o1=0.01, o2=0.99
* 3.初始权重:  
    * w1=0.15, w2=0.20, w3=0.25, w4=0.30
    * w5=0.40, w6=0.45, w7=0.50, w8=0.55

### 前向传播

> 1.输入层---->隐含层：

计算神经元h1的输入加权和：

$$
\begin{align}
net_{h1}&=w_1 * i_1 + w_2 * i_2 + w_3 * i_3
\end{align}
$$

神经元h1的输出o1:(此处用到激活函数为sigmoid函数)：

$$
\begin{align}
out_{h1}&=\frac{1}{1+e^{-net_{h1}}}
\end{align}
$$

> 2.隐含层---->输出层：

计算输出层神经元o1和o2的值：(可上面计算方式类似)

$$
\begin{align}
net_{h1}&=w_5 * out_{h1} + w_6 * out_{h2} + b_2 * 1
\end{align}
$$

$$
\begin{align}
out_{o1}&=\frac{1}{1+e^{-net_{o1}}}
\end{align}
$$

* 这样前向传播的过程就结束了，我们得到输出值为[0.75136079 , 0.772928465]，与实际值[0.01 , 0.99]相差还很远，现在我们对误差进行反向传播，更新权值，重新计算输出。

### 反向传播

> 1.计算总误差：

$$
\begin{align}
E_{total}&=\sum{\frac{1}{2}*(target-output)^2}
\end{align}
$$

> 2.隐含层---->输出层的权值更新：

![/img/DeepLearning/1.入门介绍/反向传播计算输出层权重.png)



> 3.隐含层---->隐含层的权值更新：

![/img/DeepLearning/1.入门介绍/反向传播计算隐含层的权值.png)

