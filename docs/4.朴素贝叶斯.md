   
# 4) 朴素贝叶斯

* 假设: 特征之间强（朴素）独立
* 概率模型
    * P(C|F1F2...Fn) = P(F1F2...Fn|C)P(C) / P(F1F2...Fn)
   * 由于对于所有类别，P(F1F2...Fn)都是相同的，比较P(C|F1F2...Fn)只用比较P(F1F2...Fn|C)P(C)就好了
* 朴素贝叶斯的特点
    * 优点：在数据较少的情况下仍然有效，可以处理多类别问题
    * 缺点：对于输入数据的准备方式较为敏感
    * 适用数据类型：标称型数据
* 朴素贝叶斯的一般过程
    * 收集数据：可以使用任何方法
    * 准备数据：需要数值型或者布尔型数据
    * 分析数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好。
    * 训练算法：计算不同的独立特征的条件概率
    * 测试算法：计算错误率
    * 使用算法：文本分类等
*  优化
    * 为了避免一个概率为0导致P(F1|C)*P(F2|C)....P(Fn|C)整个为0，所以优化为将所有词的出现数都初始化为1，并将分母初始化为2.
    * 由于大部分因子比较小，乘积之后得到的数不易比较，程序误差较大。所以取对数后可将乘法转化为加法：P(F1|C)*P(F2|C)....P(Fn|C)P(C) -> log(P(F1|C))+log(P(F2|C))+....+log(P(Fn|C))+log(P(C))
* 总结
    * 这一块代码比较乱，最好先把公式理一理再看
    * 可以参考一下[阮一峰的博客](http://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html)
