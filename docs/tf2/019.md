# Unicode å­—ç¬¦ä¸²

> åŸæ–‡ï¼š[https://tensorflow.google.cn/tutorials/load_data/unicode](https://tensorflow.google.cn/tutorials/load_data/unicode)

## ç®€ä»‹

å¤„ç†è‡ªç„¶è¯­è¨€çš„æ¨¡å‹é€šå¸¸ä½¿ç”¨ä¸åŒçš„å­—ç¬¦é›†æ¥å¤„ç†ä¸åŒçš„è¯­è¨€ã€‚*Unicode* æ˜¯ä¸€ç§æ ‡å‡†çš„ç¼–ç ç³»ç»Ÿï¼Œç”¨äºè¡¨ç¤ºå‡ ä¹æ‰€æœ‰è¯­è¨€çš„å­—ç¬¦ã€‚æ¯ä¸ªå­—ç¬¦ä½¿ç”¨ `0` å’Œ `0x10FFFF` ä¹‹é—´çš„å”¯ä¸€æ•´æ•°[ç ä½](https://en.wikipedia.org/wiki/Code_point)è¿›è¡Œç¼–ç ã€‚*Unicode å­—ç¬¦ä¸²*æ˜¯ç”±é›¶ä¸ªæˆ–æ›´å¤šç ä½ç»„æˆçš„åºåˆ—ã€‚

æœ¬æ•™ç¨‹ä»‹ç»äº†å¦‚ä½•åœ¨ TensorFlow ä¸­è¡¨ç¤º Unicode å­—ç¬¦ä¸²ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨æ ‡å‡†å­—ç¬¦ä¸²è¿ç®—çš„ Unicode ç­‰æ•ˆé¡¹å¯¹å…¶è¿›è¡Œæ“ä½œã€‚å®ƒä¼šæ ¹æ®å­—ç¬¦ä½“ç³»æ£€æµ‹å°† Unicode å­—ç¬¦ä¸²åˆ’åˆ†ä¸ºä¸åŒè¯ä¾‹ã€‚

```py
import tensorflow as tf 
```

## [`tf.string`](https://tensorflow.google.cn/api_docs/python/tf#string) æ•°æ®ç±»å‹

æ‚¨å¯ä»¥ä½¿ç”¨åŸºæœ¬çš„ TensorFlow [`tf.string`](https://tensorflow.google.cn/api_docs/python/tf#string) `dtype` æ„å»ºå­—èŠ‚å­—ç¬¦ä¸²å¼ é‡ã€‚Unicode å­—ç¬¦ä¸²é»˜è®¤ä½¿ç”¨ UTF-8 ç¼–ç ã€‚

```
tf.constant(u"Thanks ğŸ˜Š") 
```py

```
<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \xf0\x9f\x98\x8a'>

```py

[`tf.string`](https://tensorflow.google.cn/api_docs/python/tf#string) å¼ é‡å¯ä»¥å®¹çº³ä¸åŒé•¿åº¦çš„å­—èŠ‚å­—ç¬¦ä¸²ï¼Œå› ä¸ºå­—èŠ‚å­—ç¬¦ä¸²ä¼šè¢«è§†ä¸ºåŸå­å•å…ƒã€‚å­—ç¬¦ä¸²é•¿åº¦ä¸åŒ…æ‹¬åœ¨å¼ é‡ç»´åº¦ä¸­ã€‚

```
tf.constant([u"You're", u"welcome!"]).shape 
```py

```
TensorShape([2])

```py

æ³¨ï¼šä½¿ç”¨ Python æ„é€ å­—ç¬¦ä¸²æ—¶ï¼Œv2 å’Œ v3 å¯¹ Unicode çš„å¤„ç†æ–¹å¼æœ‰æ‰€ä¸åŒã€‚åœ¨ v2 ä¸­ï¼ŒUnicode å­—ç¬¦ä¸²ç”¨å‰ç¼€â€œuâ€è¡¨ç¤ºï¼ˆå¦‚ä¸Šæ‰€ç¤ºï¼‰ã€‚åœ¨ v3 ä¸­ï¼Œå­—ç¬¦ä¸²é»˜è®¤ä½¿ç”¨ Unicode ç¼–ç ã€‚

## è¡¨ç¤º Unicode

åœ¨ TensorFlow ä¸­æœ‰ä¸¤ç§è¡¨ç¤º Unicode å­—ç¬¦ä¸²çš„æ ‡å‡†æ–¹å¼ï¼š

*   `string` æ ‡é‡ - ä½¿ç”¨å·²çŸ¥[å­—ç¬¦ç¼–ç ](https://en.wikipedia.org/wiki/Character_encoding)å¯¹ç ä½åºåˆ—è¿›è¡Œç¼–ç ã€‚
*   `int32` å‘é‡ - æ¯ä¸ªä½ç½®åŒ…å«å•ä¸ªç ä½ã€‚

ä¾‹å¦‚ï¼Œä»¥ä¸‹ä¸‰ä¸ªå€¼å‡è¡¨ç¤º Unicode å­—ç¬¦ä¸² `"è¯­è¨€å¤„ç†"`ï¼š

```
# Unicode string, represented as a UTF-8 encoded string scalar.
text_utf8 = tf.constant(u"è¯­è¨€å¤„ç†")
text_utf8 
```py

```
<tf.Tensor: shape=(), dtype=string, numpy=b'\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86'>

```py

```
# Unicode string, represented as a UTF-16-BE encoded string scalar.
text_utf16be = tf.constant(u"è¯­è¨€å¤„ç†".encode("UTF-16-BE"))
text_utf16be 
```py

```
<tf.Tensor: shape=(), dtype=string, numpy=b'\x8b\xed\x8a\x00Y\x04t\x06'>

```py

```
# Unicode string, represented as a vector of Unicode code points.
text_chars = tf.constant([ord(char) for char in u"è¯­è¨€å¤„ç†"])
text_chars 
```py

```
<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>

```py

### åœ¨ä¸åŒè¡¨ç¤ºä¹‹é—´è¿›è¡Œè½¬æ¢

TensorFlow æä¾›äº†åœ¨ä¸‹åˆ—ä¸åŒè¡¨ç¤ºä¹‹é—´è¿›è¡Œè½¬æ¢çš„è¿ç®—ï¼š

*   [`tf.strings.unicode_decode`](https://tensorflow.google.cn/api_docs/python/tf/strings/unicode_decode)ï¼šå°†ç¼–ç çš„å­—ç¬¦ä¸²æ ‡é‡è½¬æ¢ä¸ºç ä½çš„å‘é‡ã€‚
*   [`tf.strings.unicode_encode`](https://tensorflow.google.cn/api_docs/python/tf/strings/unicode_encode)ï¼šå°†ç ä½çš„å‘é‡è½¬æ¢ä¸ºç¼–ç çš„å­—ç¬¦ä¸²æ ‡é‡ã€‚
*   [`tf.strings.unicode_transcode`](https://tensorflow.google.cn/api_docs/python/tf/strings/unicode_transcode)ï¼šå°†ç¼–ç çš„å­—ç¬¦ä¸²æ ‡é‡è½¬æ¢ä¸ºå…¶ä»–ç¼–ç ã€‚

```
tf.strings.unicode_decode(text_utf8,
                          input_encoding='UTF-8') 
```py

```
<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>

```py

```
tf.strings.unicode_encode(text_chars,
                          output_encoding='UTF-8') 
```py

```
<tf.Tensor: shape=(), dtype=string, numpy=b'\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86'>

```py

```
tf.strings.unicode_transcode(text_utf8,
                             input_encoding='UTF8',
                             output_encoding='UTF-16-BE') 
```py

```
<tf.Tensor: shape=(), dtype=string, numpy=b'\x8b\xed\x8a\x00Y\x04t\x06'>

```py

### æ‰¹æ¬¡ç»´åº¦

è§£ç å¤šä¸ªå­—ç¬¦ä¸²æ—¶ï¼Œæ¯ä¸ªå­—ç¬¦ä¸²ä¸­çš„å­—ç¬¦æ•°å¯èƒ½ä¸ç›¸ç­‰ã€‚è¿”å›ç»“æœæ˜¯ [`tf.RaggedTensor`](https://tensorflow.google.cn/guide/ragged_tensor)ï¼Œå…¶ä¸­æœ€é‡Œé¢çš„ç»´åº¦çš„é•¿åº¦ä¼šæ ¹æ®æ¯ä¸ªå­—ç¬¦ä¸²ä¸­çš„å­—ç¬¦æ•°è€Œå˜åŒ–ï¼š

```
# A batch of Unicode strings, each represented as a UTF8-encoded string.
batch_utf8 = [s.encode('UTF-8') for s in
              [u'hÃƒllo',  u'What is the weather tomorrow',  u'GÃ¶Ã¶dnight', u'ğŸ˜Š']]
batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,
                                               input_encoding='UTF-8')
for sentence_chars in batch_chars_ragged.to_list():
  print(sentence_chars) 
```py

```
[104, 195, 108, 108, 111]
[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]
[71, 246, 246, 100, 110, 105, 103, 104, 116]
[128522]

```py

æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨æ­¤ [`tf.RaggedTensor`](https://tensorflow.google.cn/api_docs/python/tf/RaggedTensor)ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ [`tf.RaggedTensor.to_tensor`](https://tensorflow.google.cn/api_docs/python/tf/RaggedTensor#to_tensor) å’Œ [`tf.RaggedTensor.to_sparse`](https://tensorflow.google.cn/api_docs/python/tf/RaggedTensor#to_sparse) æ–¹æ³•å°†å…¶è½¬æ¢ä¸ºå¸¦æœ‰å¡«å……çš„å¯†é›† [`tf.Tensor`](https://tensorflow.google.cn/api_docs/python/tf/Tensor) æˆ– [`tf.SparseTensor`](https://tensorflow.google.cn/api_docs/python/tf/sparse/SparseTensor)ã€‚

```
batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)
print(batch_chars_padded.numpy()) 
```py

```
[[   104    195    108    108    111     -1     -1     -1     -1     -1
      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1
      -1     -1     -1     -1     -1     -1     -1     -1]
 [    87    104     97    116     32    105    115     32    116    104
     101     32    119    101     97    116    104    101    114     32
     116    111    109    111    114    114    111    119]
 [    71    246    246    100    110    105    103    104    116     -1
      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1
      -1     -1     -1     -1     -1     -1     -1     -1]
 [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1
      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1
      -1     -1     -1     -1     -1     -1     -1     -1]]

```py

```
batch_chars_sparse = batch_chars_ragged.to_sparse() 
```py

åœ¨å¯¹å¤šä¸ªå…·æœ‰ç›¸åŒé•¿åº¦çš„å­—ç¬¦ä¸²è¿›è¡Œç¼–ç æ—¶ï¼Œå¯ä»¥å°† [`tf.Tensor`](https://tensorflow.google.cn/api_docs/python/tf/Tensor) ç”¨ä½œè¾“å…¥ï¼š

```
tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [ 99, 111, 119]],
                          output_encoding='UTF-8') 
```py

```
<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>

```py

å½“å¯¹å¤šä¸ªå…·æœ‰ä¸åŒé•¿åº¦çš„å­—ç¬¦ä¸²è¿›è¡Œç¼–ç æ—¶ï¼Œåº”å°† [`tf.RaggedTensor`](https://tensorflow.google.cn/api_docs/python/tf/RaggedTensor) ç”¨ä½œè¾“å…¥ï¼š

```
tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8') 
```py

```
<tf.Tensor: shape=(4,), dtype=string, numpy=
array([b'h\xc3\x83llo', b'What is the weather tomorrow',
       b'G\xc3\xb6\xc3\xb6dnight', b'\xf0\x9f\x98\x8a'], dtype=object)>

```py

å¦‚æœæ‚¨çš„å¼ é‡å…·æœ‰å¡«å……æˆ–ç¨€ç–æ ¼å¼çš„å¤šä¸ªå­—ç¬¦ä¸²ï¼Œè¯·åœ¨è°ƒç”¨ `unicode_encode` ä¹‹å‰å°†å…¶è½¬æ¢ä¸º [`tf.RaggedTensor`](https://tensorflow.google.cn/api_docs/python/tf/RaggedTensor)ï¼š

```
tf.strings.unicode_encode(
    tf.RaggedTensor.from_sparse(batch_chars_sparse),
    output_encoding='UTF-8') 
```py

```
<tf.Tensor: shape=(4,), dtype=string, numpy=
array([b'h\xc3\x83llo', b'What is the weather tomorrow',
       b'G\xc3\xb6\xc3\xb6dnight', b'\xf0\x9f\x98\x8a'], dtype=object)>

```py

```
tf.strings.unicode_encode(
    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),
    output_encoding='UTF-8') 
```py

```
<tf.Tensor: shape=(4,), dtype=string, numpy=
array([b'h\xc3\x83llo', b'What is the weather tomorrow',
       b'G\xc3\xb6\xc3\xb6dnight', b'\xf0\x9f\x98\x8a'], dtype=object)>

```py

## Unicode è¿ç®—

### å­—ç¬¦é•¿åº¦

[`tf.strings.length`](https://tensorflow.google.cn/api_docs/python/tf/strings/length) è¿ç®—å…·æœ‰ `unit` å‚æ•°ï¼Œè¯¥å‚æ•°è¡¨ç¤ºè®¡ç®—é•¿åº¦çš„æ–¹å¼ã€‚`unit` é»˜è®¤ä¸º `"BYTE"`ï¼Œä½†ä¹Ÿå¯ä»¥å°†å…¶è®¾ç½®ä¸ºå…¶ä»–å€¼ï¼ˆä¾‹å¦‚ `"UTF8_CHAR"` æˆ– `"UTF16_CHAR"`ï¼‰ï¼Œä»¥ç¡®å®šæ¯ä¸ªå·²ç¼–ç  `string` ä¸­çš„ Unicode ç ä½æ•°é‡ã€‚

```
# Note that the final character takes up 4 bytes in UTF8.
thanks = u'Thanks ğŸ˜Š'.encode('UTF-8')
num_bytes = tf.strings.length(thanks).numpy()
num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()
print('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars)) 
```py

```
11 bytes; 8 UTF-8 characters

```py

### å­—ç¬¦å­å­—ç¬¦ä¸²

ç±»ä¼¼åœ°ï¼Œ[`tf.strings.substr`](https://tensorflow.google.cn/api_docs/python/tf/strings/substr) è¿ç®—ä¼šæ¥å— "`unit`" å‚æ•°ï¼Œå¹¶ç”¨å®ƒæ¥ç¡®å®š "`pos`" å’Œ "`len`" å‚æ•°åŒ…å«çš„åç§»ç±»å‹ã€‚

```
# default: unit='BYTE'. With len=1, we return a single byte.
tf.strings.substr(thanks, pos=7, len=1).numpy() 
```py

```
b'\xf0'

```py

```
# Specifying unit='UTF8_CHAR', we return a single character, which in this case
# is 4 bytes.
print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy()) 
```py

```
b'\xf0\x9f\x98\x8a'

```py

### æ‹†åˆ† Unicode å­—ç¬¦ä¸²

[`tf.strings.unicode_split`](https://tensorflow.google.cn/api_docs/python/tf/strings/unicode_split) è¿ç®—ä¼šå°† Unicode å­—ç¬¦ä¸²æ‹†åˆ†ä¸ºå•ä¸ªå­—ç¬¦çš„å­å­—ç¬¦ä¸²ï¼š

```
tf.strings.unicode_split(thanks, 'UTF-8').numpy() 
```py

```
array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\xf0\x9f\x98\x8a'],
      dtype=object)

```py

### å­—ç¬¦çš„å­—èŠ‚åç§»é‡

ä¸ºäº†å°† [`tf.strings.unicode_decode`](https://tensorflow.google.cn/api_docs/python/tf/strings/unicode_decode) ç”Ÿæˆçš„å­—ç¬¦å¼ é‡ä¸åŸå§‹å­—ç¬¦ä¸²å¯¹é½ï¼Œäº†è§£æ¯ä¸ªå­—ç¬¦å¼€å§‹ä½ç½®çš„åç§»é‡å¾ˆæœ‰ç”¨ã€‚æ–¹æ³• [`tf.strings.unicode_decode_with_offsets`](https://tensorflow.google.cn/api_docs/python/tf/strings/unicode_decode_with_offsets) ä¸ `unicode_decode` ç±»ä¼¼ï¼Œä¸åŒçš„æ˜¯å®ƒä¼šè¿”å›åŒ…å«æ¯ä¸ªå­—ç¬¦èµ·å§‹åç§»é‡çš„ç¬¬äºŒå¼ é‡ã€‚

```
codepoints, offsets = tf.strings.unicode_decode_with_offsets(u"ğŸˆğŸ‰ğŸŠ", 'UTF-8')

for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):
  print("At byte offset {}: codepoint {}".format(offset, codepoint)) 
```py

```
At byte offset 0: codepoint 127880
At byte offset 4: codepoint 127881
At byte offset 8: codepoint 127882

```py

## Unicode å­—ç¬¦ä½“ç³»

æ¯ä¸ª Unicode ç ä½éƒ½å±äºæŸä¸ªç ä½é›†åˆï¼Œè¿™äº›é›†åˆè¢«ç§°ä½œ[å­—ç¬¦ä½“ç³»](https://en.wikipedia.org/wiki/Script_%28Unicode%29)ã€‚æŸä¸ªå­—ç¬¦çš„å­—ç¬¦ä½“ç³»æœ‰åŠ©äºç¡®å®šè¯¥å­—ç¬¦å¯èƒ½æ‰€å±çš„è¯­è¨€ã€‚ä¾‹å¦‚ï¼Œå·²çŸ¥ 'Ğ‘' å±äºè¥¿é‡Œå°”å­—ç¬¦ä½“ç³»ï¼Œè¡¨æ˜åŒ…å«è¯¥å­—ç¬¦çš„ç°ä»£æ–‡æœ¬å¾ˆå¯èƒ½æ¥è‡ªæŸä¸ªæ–¯æ‹‰å¤«è¯­ç§ï¼ˆå¦‚ä¿„è¯­æˆ–ä¹Œå…‹å…°è¯­ï¼‰ã€‚

TensorFlow æä¾›äº† [`tf.strings.unicode_script`](https://tensorflow.google.cn/api_docs/python/tf/strings/unicode_script) è¿ç®—æ¥ç¡®å®šæŸä¸€ç»™å®šç ä½ä½¿ç”¨çš„æ˜¯å“ªä¸ªå­—ç¬¦ä½“ç³»ã€‚å­—ç¬¦ä½“ç³»ä»£ç æ˜¯å¯¹åº”äº[å›½é™… Unicode ç»„ä»¶](http://site.icu-project.org/home) (ICU) [`UScriptCode`](http://icu-project.org/apiref/icu4c/uscript_8h.html) å€¼çš„ `int32` å€¼ã€‚

```
uscript = tf.strings.unicode_script([33464, 1041])  # ['èŠ¸', 'Ğ‘']

print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC] 
```py

```
[17  8]

```py

[`tf.strings.unicode_script`](https://tensorflow.google.cn/api_docs/python/tf/strings/unicode_script) è¿ç®—è¿˜å¯ä»¥åº”ç”¨äºç ä½çš„å¤šç»´ [`tf.Tensor`](https://tensorflow.google.cn/api_docs/python/tf/Tensor) æˆ– [`tf.RaggedTensor`](https://tensorflow.google.cn/api_docs/python/tf/RaggedTensor)ï¼š

```
print(tf.strings.unicode_script(batch_chars_ragged)) 
```py

```
<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>

```py

## ç¤ºä¾‹ï¼šç®€å•åˆ†è¯

åˆ†è¯æ˜¯å°†æ–‡æœ¬æ‹†åˆ†ä¸ºç±»ä¼¼å•è¯çš„å•å…ƒçš„ä»»åŠ¡ã€‚å½“ä½¿ç”¨ç©ºæ ¼å­—ç¬¦åˆ†éš”å•è¯æ—¶ï¼Œè¿™é€šå¸¸å¾ˆå®¹æ˜“ï¼Œä½†æ˜¯æŸäº›è¯­è¨€ï¼ˆå¦‚ä¸­æ–‡å’Œæ—¥è¯­ï¼‰ä¸ä½¿ç”¨ç©ºæ ¼ï¼Œè€ŒæŸäº›è¯­è¨€ï¼ˆå¦‚å¾·è¯­ï¼‰ä¸­å­˜åœ¨é•¿å¤åˆè¯ï¼Œå¿…é¡»è¿›è¡Œæ‹†åˆ†æ‰èƒ½åˆ†æå…¶å«ä¹‰ã€‚åœ¨ç½‘é¡µæ–‡æœ¬ä¸­ï¼Œä¸åŒè¯­è¨€å’Œå­—ç¬¦ä½“ç³»å¸¸å¸¸æ··åˆåœ¨ä¸€èµ·ï¼Œä¾‹å¦‚â€œNY æ ªä¾¡â€ï¼ˆçº½çº¦è¯åˆ¸äº¤æ˜“æ‰€ï¼‰ã€‚

æˆ‘ä»¬å¯ä»¥åˆ©ç”¨å­—ç¬¦ä½“ç³»çš„å˜åŒ–è¿›è¡Œç²—ç•¥åˆ†è¯ï¼ˆä¸å®ç°ä»»ä½• ML æ¨¡å‹ï¼‰ï¼Œä»è€Œä¼°ç®—è¯è¾¹ç•Œã€‚è¿™å¯¹ç±»ä¼¼ä¸Šé¢â€œNY æ ªä¾¡â€ç¤ºä¾‹çš„å­—ç¬¦ä¸²éƒ½æœ‰æ•ˆã€‚è¿™ç§æ–¹æ³•å¯¹å¤§å¤šæ•°ä½¿ç”¨ç©ºæ ¼çš„è¯­è¨€ä¹Ÿéƒ½æœ‰æ•ˆï¼Œå› ä¸ºå„ç§å­—ç¬¦ä½“ç³»ä¸­çš„ç©ºæ ¼å­—ç¬¦éƒ½å½’ç±»ä¸º USCRIPT_COMMONï¼Œè¿™æ˜¯ä¸€ç§ç‰¹æ®Šçš„å­—ç¬¦ä½“ç³»ä»£ç ï¼Œä¸åŒäºä»»ä½•å®é™…æ–‡æœ¬ã€‚

```
# dtype: string; shape: [num_sentences]
#
# The sentences to process.  Edit this line to try out different inputs!
sentence_texts = [u'Hello, world.', u'ä¸–ç•Œã“ã‚“ã«ã¡ã¯'] 
```py

é¦–å…ˆï¼Œæˆ‘ä»¬å°†å¥å­è§£ç ä¸ºå­—ç¬¦ç ä½ï¼Œç„¶åæŸ¥æ‰¾æ¯ä¸ªå­—ç¬¦çš„å­—ç¬¦ä½“ç³»æ ‡è¯†ç¬¦ã€‚

```
# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]
#
# sentence_char_codepoint[i, j] is the codepoint for the j'th character in
# the i'th sentence.
sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')
print(sentence_char_codepoint)

# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]
#
# sentence_char_scripts[i, j] is the unicode script of the j'th character in
# the i'th sentence.
sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)
print(sentence_char_script) 
```py

```
<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>
<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 20, 20, 20, 20, 20]]>

```py

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™äº›å­—ç¬¦ä½“ç³»æ ‡è¯†ç¬¦æ¥ç¡®å®šæ·»åŠ è¯è¾¹ç•Œçš„ä½ç½®ã€‚æˆ‘ä»¬åœ¨æ¯ä¸ªå¥å­çš„å¼€å¤´æ·»åŠ ä¸€ä¸ªè¯è¾¹ç•Œï¼›å¦‚æœæŸä¸ªå­—ç¬¦ä¸å‰ä¸€ä¸ªå­—ç¬¦å±äºä¸åŒçš„å­—ç¬¦ä½“ç³»ï¼Œä¹Ÿä¸ºè¯¥å­—ç¬¦æ·»åŠ è¯è¾¹ç•Œã€‚

```
# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]
#
# sentence_char_starts_word[i, j] is True if the j'th character in the i'th
# sentence is the start of a word.
sentence_char_starts_word = tf.concat(
    [tf.fill([sentence_char_script.nrows(), 1], True),
     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])],
    axis=1)

# dtype: int64; shape: [num_words]
#
# word_starts[i] is the index of the character that starts the i'th word (in
# the flattened list of characters from all sentences).
word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)
print(word_starts) 
```py

```
tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)

```py

ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™äº›èµ·å§‹åç§»é‡æ¥æ„å»º `RaggedTensor`ï¼Œå®ƒåŒ…å«äº†æ‰€æœ‰æ‰¹æ¬¡çš„å•è¯åˆ—è¡¨ï¼š

```
# dtype: int32; shape: [num_words, (num_chars_per_word)]
#
# word_char_codepoint[i, j] is the codepoint for the j'th character in the
# i'th word.
word_char_codepoint = tf.RaggedTensor.from_row_starts(
    values=sentence_char_codepoint.values,
    row_starts=word_starts)
print(word_char_codepoint) 
```py

```
<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>

```py

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥å°†è¯ç ä½ `RaggedTensor` åˆ’åˆ†å›å¥å­ä¸­ï¼š

```
# dtype: int64; shape: [num_sentences]
#
# sentence_num_words[i] is the number of words in the i'th sentence.
sentence_num_words = tf.reduce_sum(
    tf.cast(sentence_char_starts_word, tf.int64),
    axis=1)

# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]
#
# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character
# in the j'th word in the i'th sentence.
sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(
    values=word_char_codepoint,
    row_lengths=sentence_num_words)
print(sentence_word_char_codepoint) 
```py

```
<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>

```py

ä¸ºäº†ä½¿æœ€ç»ˆç»“æœæ›´æ˜“äºé˜…è¯»ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶é‡æ–°ç¼–ç ä¸º UTF-8 å­—ç¬¦ä¸²ï¼š

```
tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list() 
```py

```
[[b'Hello', b', ', b'world', b'.'],
 [b'\xe4\xb8\x96\xe7\x95\x8c',
  b'\xe3\x81\x93\xe3\x82\x93\xe3\x81\xab\xe3\x81\xa1\xe3\x81\xaf']]

```